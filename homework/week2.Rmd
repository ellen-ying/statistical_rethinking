---
title: "Week 2 Homework"
author: "Yurun (Ellen) Ying"
date: "5/24/2022"
output: github_document
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(19990331)
```

## Problems from the book

### 4M7
Refit the model `m4.3` without the `xbar`. Compare the covariance of parameters and the posterior predictions.

```{r, message=FALSE}
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[ d$age >= 18,]
xbar <- mean(d2$weight)

# the original model
m4.3 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <-  a + b * (weight - xbar),
    a ~ dnorm(178, 20),
    b ~ dlnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d2
)

# checkout the model
precis(m4.3)

# have little covariance due to centering
round(vcov(m4.3), 3) 

# posterior predictions
weight.seq <- seq(from = 25, to = 70, by = 1)
mu <- link(m4.3, data = data.frame(weight = weight.seq))
mu.mean <- apply(mu, 2, mean) # calculate the mean for each column
mu.PI <- apply(mu, 2, PI, prob = 0.89)
sim.height <- sim(m4.3, data = data.frame(weight = weight.seq))
height.PI <- apply(sim.height, 2, PI, prob = 0.89)

plot(height ~ weight, data = d2, col = col.alpha(rangi2, 0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)
```

Fit a new model

```{r}
# the original model
m4.3_n <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <-  a + b * weight,
    a ~ dnorm(178, 20),
    b ~ dlnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d2
)

# checkout the model
precis(m4.3_n)

# have little covariance due to centering
round(vcov(m4.3_n), 3) 

# posterior predictions
mu <- link(m4.3_n, data = data.frame(weight = weight.seq))
mu.mean <- apply(mu, 2, mean) # calculate the mean for each column
mu.PI <- apply(mu, 2, PI, prob = 0.89)
sim.height <- sim(m4.3_n, data = data.frame(weight = weight.seq))
height.PI <- apply(sim.height, 2, PI, prob = 0.89)

plot(height ~ weight, data = d2, col = col.alpha(rangi2, 0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)

```

There is covariance among the parameters when the data is not centered, but there doesn't seem to be much difference between the posterior predictions.

### 4H1

Predict some individuals' height in the Howell data.
```{r}
weight.seq <- c(46.95, 43.72, 64.78, 32.59, 54.63)
mu <- link(m4.3, data = list(weight = weight.seq))
mu.mean <- apply(mu, 2, mean)
height_sim <- sim(m4.3, data = list(weight = weight.seq))
height_PI <- apply(height_sim, 2, PI, 0.89)
data.frame(
  Individual = seq(1, 5, 1),
  weight = weight.seq,
  expected_height = round(mu.mean, 2),
  PI89_LL = round(height_PI[1, ], 2),
  PI89_UL = round(height_PI[2, ], 2)
)
```
### 4H2
Fit a linear model to the data below the age of 18 in the Howell data

```{r}
d3 <- d[d$age < 18,]
xbar <- mean(d3$weight)

# plot the raw data
plot(height ~ weight, data = d3)

# fit a linear model
m_4h2 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b*(weight - xbar),
    a ~ dnorm(140, 20),
    b ~ dlnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d3
)

# inspect the model
precis(m_4h2)

# posterior predictions
weight_seq <- seq(0, 50, length.out = 30)
mu <- link(m_4h2, data = data.frame(weight = weight_seq))
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.89)
h_sim <- sim(m_4h2, data = data.frame(weight = weight_seq))
h_PI <- apply(h_sim, 2, PI, prob = 0.89)
plot(height ~ weight, data = d3, col = col.alpha(rangi2, 0.3),
     xlim = range(weight_seq), ylim = c(50, 160),
     xlab = "weight (kg)", ylab = "height (cm)")
lines(weight_seq, mu_mean)
shade(mu_PI, weight_seq)
shade(h_PI, weight_seq)

```

A non-linear model seems to fit better to the data. I would add higher-order terms to the model to fit a curve.


### 4H3

Fit a model of height and logarithm of body weight in the entire Howell data.

```{r}
# compute the logarithmof weight
d$log_w <- log(d$weight)
xbar <- log(mean(d$weight))

# fit the model
m_4h3 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b*(log_w - xbar),
    a ~ dnorm(140, 20),
    b ~ dlnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d
)

# inspect the model
# when weight is multiplied by exp(1), height increases by 47.07cm
precis(m_4h3)

# posterior prediction
weight_seq <- seq(0, 65, length.out = 30)
mu <- link(m_4h3, data = data.frame(log_w = log(weight_seq)))
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.97)
h_sim <- sim(m_4h3, data = data.frame(log_w = log(weight_seq)))
h_PI <- apply(h_sim, 2, PI, prob = 0.97)
plot(height ~ weight, data = d, col = col.alpha(rangi2, 0.3),
     xlim = range(weight_seq), ylim = c(50, 180),
     xlab = "weight (kg)", ylab = "height (cm)")
lines(weight_seq, mu_mean)
shade(mu_PI, weight_seq)
shade(h_PI, weight_seq)
```

Looks like a very very legit model...


### 4H4

Prior predicative distribution of the parabolic polynomial regression model.

- h~i~ ~ normal(mu~i~, sigma)
- mu~i~ = a + b~1~x~i~ + b~2~x~i~^2^
- a ~ normal(178, 20)
- b~1~ ~ log-normal(0, 1)
- b~2~ ~ normal(0, 1)
- sigma ~ uniform(0, 50)

```{r}
d$weight_s <- (d$weight - mean(d$weight)) / sd(d$weight)
n <- 100
a <- rnorm(n = n, 178, 20)
b1 <- rlnorm(n = n, 0, 1)
b2 <- rnorm(n = n, 0, 1)
plot(NULL, xlim = range(d$weight_s), ylim = c(-100, 300),
     xlab = "weight (kg)", ylab = "height (cm)")
for (i in 1:n)
  curve(
    a[i] + b1[i]*x + b2[i]*x^2,
    from = min(d$weight_s), to = max(d$weight_s), 
    col = col.alpha("black", 0.3), add = TRUE)
abline(h = 0, lwd = 0.5, lty = 2)
abline(h = 272, lwd = 0.5, lty = 2)
```

### 4H5

A linear model of blossom date and temperature.
```{r}
data("cherry_blossoms")
d <- cherry_blossoms
d2 <- d[complete.cases(d$doy, d$temp),] # select complete cases on doy
xbar <- mean(d2$temp)

# plot the raw data
plot(doy ~ temp, data = d2)

# pick priors
n <- 100
a <- rnorm(n, 105, 20)
b <- rnorm(n, 0, 1) 
plot(NULL, xlim = range(d2$temp), ylim = c(0, 200),
     xlab = "March temperature", ylab = "Blossom date")
for (i in 1:n)
  curve(a[i] + b[i]*x,
        from = min(d2$temp), to = max(d2$temp),
        add = TRUE, col = col.alpha("black", 0.3))

# fit the data
m_4h5 <- quap(
  alist(
    doy ~ dnorm(mu, sigma),
    mu <- a + b*(temp - xbar),
    a ~ dnorm(105, 20),
    b ~ dnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d2
)

precis(m_4h5)

# posterior predicative simulation
temp_seq <- seq(4, 9, length.out = 30)
mu <- link(m_4h5, data = data.frame(temp = temp_seq))
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.89)
day_sim <- sim(m_4h5, data = data.frame(temp = temp_seq))
day_PI <- apply(day_sim, 2, PI, prob = 0.89)

# plot
plot(doy ~ temp, data = d2, xlim = range(temp_seq), ylim = c(80, 130),
     xlab = "March temperature", ylab = "Blossom date",
     col = col.alpha(rangi2, 0.3))
lines(temp_seq, mu_mean)
shade(mu_PI, temp_seq)
shade(day_PI, temp_seq)
```

Higher temperature predicts earlier days of blossom. The linear model doesn't seem to fit the data very well. A parabolic curve may do the job better.


### 4H6
Prior predicative distribution of the spline model on cherry blossom data.
```{r}
d <- cherry_blossoms
d2 <- d[complete.cases(d$doy),] # select complete cases on doy
num_knots <- 15
knot_list <- quantile(d2$year, probs = seq(0, 1, length.out = num_knots))

# create basis functions
library(splines)
# construct cubic splines
B <- bs(d2$year, 
        knots = knot_list[-c(1, num_knots)], # get rid of the first and the last knots
        degree = 3,
        intercept = TRUE
        )

# priors
n <- 100
a <-  rnorm(n, 100, 10)
w <- rnorm(n, 0, 30)

# plot the prior predicative distribution
plot(NULL, xlim = range(d2$year), ylim = c(-200, 300),
     xlab = "year", ylab = "blossom date")
for (i in 1:n) 
  lines(d2$year, a[i] + sapply(1:nrow(B), function(j) sum(B[j,] * w[i])),
         #from = min(d2$year), to = max(d2$year),
         col = col.alpha("black", 0.3))

```

The prior on weights seem to be specifying the range of the predicted variable.

### 4H8
Refit the cherry blossom data without the intercept
```{r}
# construct cubic splines
B <- bs(d2$year, 
        knots = knot_list[-c(1, num_knots)], # get rid of the first and the last knots
        degree = 3,
        intercept = TRUE
        )

# plot the basis functions
plot(NULL, xlim = range(d2$year), ylim = c(0, 1),
     xlab = "year", ylab = "basis")
for (i in 1:ncol(B)) lines(d2$year, B[,i])

# fit the model
# get the first basis function
B0 <- B[,1]
B_rest <- B[,2:ncol(B)]

m_4h8 <- quap(
  alist(
    D ~ dnorm(mu, sigma),
    mu <-  B0 * w0 + B_rest %*% w,
    w0 ~ dnorm(100, 10),
    w ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = data.frame(D = d2$doy, B0 = B0, B_rest = B_rest),
  start = list(w = rep(0, ncol(B_rest)))
)

precis(m_4h8, depth = 2)

# here are the weighted basis functions
post <- extract.samples(m_4h8)
w0 <- mean(post$w0)
w <- apply(post$w, 2, mean)
plot(NULL, xlim = range(d2$year), ylim = c(-100, 110),
     xlab = "year", ylab = "basis * weight")
for (i in 1:ncol(B_rest)) lines(d2$year, w0 * B0 + w[i]*B_rest[,i])

# a curve for the mean and its interval
mu <- link(m_4h8)
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.89)
plot(doy ~ year, data = d2, col = col.alpha(rangi2, 0.3), pch = 16)
lines(d2$year, mu_mean)
shade(mu_PI, d2$year)
```

The model is generally identical to the one using an intercept, but there is a small difference where the intercept of the curve lies on the y axis.

## Course homework

### Problem 1

Construct regression model of weight by height, using the data of adult individuals. Use the model to predict 3 individuals' expected weight and 89% interval.
```{r}
d <- Howell1
d <- d[d$age >=18, ]
xbar <- mean(d$height)

# choose priors and do prior predicative simulation
n <- 100
a <- rnorm(n, 55, 10)
b <- rlnorm(n, 0, 0.2)
plot(NULL, xlim = range(d$height), ylim = c(0, 100),
     xlab = "height (cm)", ylab = "weight(kg)")
for(i in 1:n)
  curve(
    a[i] + b[i] * (x - xbar),
    from = min(d$height), to = max(d$height),
    col = col.alpha("black", 0.3), add = TRUE
  )

# fit a model
m_p1 <- quap(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a + b * (height - xbar),
    a ~ dnorm(55, 10),
    b ~ dlnorm(0, 0.2),
    sigma ~ dexp(1)
  ),
  data = d
)
precis(m_p1)

# posterior predicative simulation
height_seq <- seq(135, 180, length.out = 50)
mu <- link(m_p1, data = data.frame(height = height_seq))
weight_sim <- sim(m_p1, data = data.frame(height = height_seq))
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.89)
weight_PI <- apply(weight_sim, 2, PI, prob = 0.89)
plot(weight ~ height, data = d,
     xlim = range(height_seq), ylim = range(d$weight),
     xlab = "height (cm)", ylab = "weight(kg)",
     col = col.alpha(rangi2, 0.3))
lines(height_seq, mu_mean)
shade(mu_PI, height_seq)
shade(weight_PI, height_seq)

# predict three individuals
h <- c(140, 160, 175)
mu <- link(m_p1, data = data.frame(height = h))
exp_mu <- apply(mu, 2, mean)
weight_sim <- sim(m_p1, data = data.frame(height = h))
# can directly take the mean value of the simualted values to get the mean
weight_PI <- apply(weight_sim, 2, PI, prob = 0.89)
data.frame(
  Individual = c(1, 2, 3),
  height = h,
  exp_weight = round(exp_mu, 2),
  PI_LL = round(weight_PI[1, ], 2),
  PI_UL = round(weight_PI[2, ], 2)
)
```


## Problem 2

Using data younger than 13, estimate the total causal effect of age on weight.
```{r}
d <- Howell1
d <- d[d$age < 13, ]
xbar <- mean(d$age)

# choosing the priors
n <- 100
a <- rnorm(n, 20, 5)
b <- rlnorm(n, 0, 0.3)
plot(NULL, xlim = range(d$age), ylim = c(0, 50),
     xlab = "age", ylab = "weight (kg)")
for (i in 1:100)
  curve(
    a[i] + b[i] * (x - xbar),
    from = min(d$age), to =max(d$age),
    col = col.alpha("black", 0.3), add = TRUE
  )

# fit the model
m_p2 <- quap(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a + b*(age - xbar),
    a ~ dnorm(20, 5),
    b ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ),
  data = d
)

precis(m_p2)

# posterior predicative simulation
age_seq <- seq(0, 13, 1)
mu <- link(m_p2, data = list(age = age_seq))
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.89)
weight_sim <- sim(m_p2, data = list(age = age_seq))
weight_PI <- apply(weight_sim, 2, PI, prob = 0.89)
plot(weight ~ age, data = d,
     xlim = range(age_seq), ylim = c(0, 35),
     xlab = "age", ylab = "weight (kg)",
     col = col.alpha(rangi2, 0.3))
lines(age_seq, mu_mean)
shade(mu_PI, age_seq)
shade(weight_PI, age_seq)

```

Each year of growth adds to weight by 1.3kg on average.

### Problem 3

```{r}
d_sex <- list(
  age = d$age,
  weight = d$weight,
  sex = d$male + 1
)

# fit the model for two sexes separately
m_p3 <- quap(
  alist(
    weight ~ dnorm(mu, sigma),
    mu <- a[sex] + b[sex]*(age - xbar),
    a[sex] ~ dnorm(20, 5),
    b[sex] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ),
  data = d_sex
)

precis(m_p3, depth = 2)

# posterior simulation
age_seq <- seq(0, 13, 1)
mu_f <- link(m_p3, data = list(age = age_seq, sex = rep(1, 14)))
mu_m <- link(m_p3, data = list(age = age_seq, sex = rep(2, 14)))
m_contrast <- mu_m - mu_f
plot(NULL, xlim = range(age_seq), ylim = c(-2, 4),
     xlab = "age", ylab = "weight difference (boys-girls)")
for (p in c(0.5, 0.6, 0.7, 0.8, 0.9, 0.99))
  shade(apply(m_contrast, 2, PI, prob = p), age_seq)
abline(h = 0, lty = 2)
```

At all ages, boys are heavier than girls.

#### Some correction
Correction on contrast.
```{r}
# You can plot the posterior mean to have a rough sense of sex difference.
plot(weight ~ age, data = d_sex, lwd = 3, col = ifelse(d_sex$sex == 2, 4, 2),
     xlab = "age", ylab = "weight(kg0")
age_seq <- seq(0, 13, 1)
mu_f <- link(m_p3, data = list(age = age_seq, sex = rep(1, 14)))
lines(age_seq, apply(mu_f, 2, mean), lwd = 3, col = 2)
shade(apply(mu_f, 2, PI, prob = 0.89), age_seq, col = col.alpha(2, 0.3))
mu_m <- link(m_p3, data = list(age = age_seq, sex = rep(2, 14)))
lines(age_seq, apply(mu_m, 2, mean), lwd = 3, col = 4)
shade(apply(mu_m, 2, PI, prob = 0.89), age_seq, col = col.alpha(4, 0.3))

# in the contrast, compare the entire weight distribution instead of the expectation
# boys tend to be heavier than girls, but the distribution overlaps a lot
sim_f <- sim(m_p3, data = list(age = age_seq, sex = rep(1, 14)))
sim_m <- sim(m_p3, data = list(age = age_seq, sex = rep(2, 14)))
m_contrast <- sim_m - sim_f
plot(NULL, xlim = range(age_seq), ylim = c(-15, 15),
     xlab = "age", ylab = "weight difference (boys-girls)")
for (p in c(0.5, 0.6, 0.7, 0.8, 0.9, 0.99))
  shade(apply(m_contrast, 2, PI, prob = p), age_seq)
abline(h = 0, lty = 2)
```


### Problem 4

#### My attempt
Model growth in the `Oxboys` dataset.
```{r, message=FALSE}
library(tidyverse)
data("Oxboys")
d <- 
  as_tibble(Oxboys) %>% 
  select(-age) %>% 
  pivot_wider(names_from = "Occasion", values_from = "height") %>% 
  select(-Subject)

# calculate the increments
ox <- 
  data.frame(
    sapply(1:(length(names(d)) - 1),
           function(i) d[,i+1] - d[,i])
  ) %>% 
  pivot_longer(everything(), 
               names_to = "occasion", names_prefix = "X", values_to = "growth") %>% 
  mutate(
    occasion = as.numeric(occasion) - 1
  )

# check the data
plot(growth ~ occasion, data = ox)

# seems good to fit a spline
library(splines)
num_knots <- 4
knot_list <- quantile(ox$occasion, probs = seq(0, 1, length.out = num_knots))
B <- bs(ox$occasion, 
        knots = knot_list[-c(1, num_knots)],
        degree = 3,
        intercept = TRUE
        )

# basis function
plot(NULL, xlim = c(1, 8), ylim = c(0, 1),
     xlab = "occasion", ylab = "basis")
for (i in 1:ncol(B)) lines(ox$occasion, B[, i])

# choose priors
n <- 100
a <- rnorm(n, 3, 1)
w <- rlnorm(n, 0, 0.7)
plot(NULL, xlim = c(1, 8), ylim = c(-2, 6),
     xlab = "occasion", ylab = "growth")
for (i in 1:n)
  lines(ox$occasion, 
        sapply(1:nrow(B), function(j) sum(B[j,] * w[i])),
        col = col.alpha("black", 0.3))

# fit the model
m_p4 <- quap(
  alist(
    growth ~ dnorm(mu, sigma),
    mu ~ a + B %*% w,
    a ~ dnorm(3, 1),
    w ~ dlnorm(0, 0.7),
    sigma ~ dexp(1)
  ),
  data = data.frame(growth = ox$growth, B = B),
  start = list(w = rep(1, ncol(B)))
)

# weight basis functions
post <- extract.samples(m_p4)
mu_mean <- apply(post$w, 2, mean)
plot(NULL, xlim = c(1, 8), ylim = c(0, 5),
     xlab = "occasion", ylab = "basis")
for (i in 1:ncol(B)) lines(ox$occasion, B[, i] * w[i])

# posterior
mu <- link(m_p4)
mu_mean <- apply(mu, 2, mean)
mu_PI <- apply(mu, 2, PI, prob = 0.89)
plot(growth ~ occasion, data = ox, col = col.alpha(rangi2, 0.3), pch = 16,
     xlim = c(1, 8), ylim = c(0, 5),
     xlab = "occasion", ylab = "growth")
lines(ox$occasion, mu_mean)
shade(mu_PI, ox$occasion)
```

Doesn't seem to make sense...


#### More legit answer

This is really only a problem of modeling one variable.
```{r}
m_p4 <- quap(
  alist(
    growth ~ dlnorm(alpha, sigma),
    alpha ~ dnorm(0, 0.1),
    sigma ~ dexp(3)
  ),
  data = ox
)

# posterior distribution
post <- extract.samples(m_p4)
dsim <- rlnorm(1e4, post$alpha, post$sigma)
dens(dsim)

# sum over 8 occassions of growth
inc_sum <- 
  sapply(1:1000,
         function(s) sum(rlnorm(8, post$alpha[s], post$sigma[s])))
dens(inc_sum)
```

